import { modelCacheService } from './cacheService';
import { swManager } from './swManager';

interface ModelConfig {
    id: string;
    name: string;
    size: string;
    loadTime: string;
    quality: 'basic' | 'good' | 'excellent';
    url?: string;
}

class FastChatService {
    private currentModel: string | null = null;
    private isInitialized = false;
    private loadingPromise: Promise<void> | null = null;
    private instantResponses: Map<string, string> = new Map();

    // é¢„å®šä¹‰çš„è½»é‡çº§æ¨¡å‹é…ç½®
    private readonly FAST_MODELS: ModelConfig[] = [
        {
            id: 'instant',
            name: 'å³æ—¶å›å¤',
            size: '0MB',
            loadTime: '<100ms',
            quality: 'basic'
        },
        {
            id: 'Xenova/distilgpt2',
            name: 'DistilGPT-2',
            size: '40MB',
            loadTime: '10-30s',
            quality: 'basic'
        },
        {
            id: 'Xenova/gpt2',
            name: 'GPT-2',
            size: '124MB',
            loadTime: '30-60s',
            quality: 'good'
        },
        {
            id: 'Xenova/TinyLlama-1.1B-Chat-v1.0',
            name: 'TinyLlama',
            size: '600MB',
            loadTime: '2-5min',
            quality: 'excellent'
        }
    ];

    constructor() {
        this.initInstantResponses();
    }

    async init(): Promise<void> {
        if (this.loadingPromise) {
            return this.loadingPromise;
        }

        this.loadingPromise = this.performInit();
        return this.loadingPromise;
    }

    private async performInit(): Promise<void> {
        try {
            console.log('ğŸš€ åˆå§‹åŒ–å¿«é€ŸèŠå¤©æœåŠ¡...');

            // æ³¨å†Œ Service Worker
            const swSuccess = await swManager.register();
            if (swSuccess) {
                console.log('âœ… Service Worker æ³¨å†ŒæˆåŠŸ');
            }

            // åˆå§‹åŒ– IndexedDB
            await modelCacheService.init();
            console.log('âœ… IndexedDB åˆå§‹åŒ–æˆåŠŸ');

            // æ¸…ç†æ—§ç¼“å­˜ï¼ˆä¿ç•™7å¤©ï¼‰
            const cleanedCount = await modelCacheService.cleanOldCache();
            if (cleanedCount > 0) {
                console.log(`ğŸ§¹ æ¸…ç†äº† ${cleanedCount} ä¸ªæ—§ç¼“å­˜é¡¹`);
            }

            this.isInitialized = true;
            console.log('ğŸ‰ å¿«é€ŸèŠå¤©æœåŠ¡åˆå§‹åŒ–å®Œæˆ');

        } catch (error) {
            console.error('âŒ å¿«é€ŸèŠå¤©æœåŠ¡åˆå§‹åŒ–å¤±è´¥:', error);
            throw error;
        }
    }

    async quickResponse(question: string): Promise<{
        response: string;
        source: 'cache' | 'instant' | 'model';
        modelId: string;
        loadTime: number;
    }> {
        const startTime = Date.now();

        if (!this.isInitialized) {
            await this.init();
        }

        try {
            // 1. é¦–å…ˆæ£€æŸ¥ç¼“å­˜çš„å“åº”
            const cachedResponse = await this.checkCachedResponse(question);
            if (cachedResponse) {
                return {
                    response: cachedResponse.response,
                    source: 'cache',
                    modelId: cachedResponse.modelId,
                    loadTime: Date.now() - startTime
                };
            }

            // 2. æ£€æŸ¥å³æ—¶å›å¤ï¼ˆå¤§å¹…å‡å°‘åŒ¹é…èŒƒå›´ï¼‰
            const instantResponse = this.getInstantResponse(question);
            if (instantResponse) {
                // ç¼“å­˜å³æ—¶å›å¤
                await modelCacheService.cacheResponse(question, instantResponse, 'instant');

                return {
                    response: instantResponse,
                    source: 'instant',
                    modelId: 'instant',
                    loadTime: Date.now() - startTime
                };
            }

            // 3. å°è¯•åŠ è½½å¹¶ä½¿ç”¨æ¨¡å‹ï¼ˆä¼˜å…ˆä½¿ç”¨çœŸå®æ¨¡å‹ï¼‰
            console.log('ğŸ¤– é—®é¢˜æœªåŒ¹é…å³æ—¶å›å¤ï¼Œå°è¯•ä½¿ç”¨çœŸå®æ¨¡å‹...');
            const modelResponse = await this.loadAndRespond(question);

            return {
                response: modelResponse.response,
                source: 'model',
                modelId: modelResponse.modelId,
                loadTime: Date.now() - startTime
            };

        } catch (error) {
            console.error('âŒ å¿«é€Ÿå“åº”å¤±è´¥:', error);

            return {
                response: 'æŠ±æ­‰ï¼Œå½“å‰æœåŠ¡æš‚æ—¶ä¸å¯ç”¨ã€‚è¯·ç¨åé‡è¯•æˆ–æ£€æŸ¥ç½‘ç»œè¿æ¥ã€‚',
                source: 'instant',
                modelId: 'error',
                loadTime: Date.now() - startTime
            };
        }
    }

    private async checkCachedResponse(question: string): Promise<{
        response: string;
        modelId: string;
    } | null> {
        // æ£€æŸ¥æ‰€æœ‰å¯èƒ½çš„æ¨¡å‹ç¼“å­˜
        for (const model of this.FAST_MODELS) {
            const cachedResponse = await modelCacheService.getCachedResponse(question, model.id);
            if (cachedResponse) {
                console.log('âš¡ ä»ç¼“å­˜è¿”å›å“åº”:', model.id);
                return {
                    response: cachedResponse,
                    modelId: model.id
                };
            }
        }

        // æœç´¢ç›¸ä¼¼é—®é¢˜
        const similarResponses = await modelCacheService.searchSimilarResponses(question, 'instant', 1);
        if (similarResponses.length > 0) {
            console.log('ğŸ” æ‰¾åˆ°ç›¸ä¼¼é—®é¢˜çš„ç¼“å­˜å“åº”');
            return {
                response: similarResponses[0].response,
                modelId: similarResponses[0].modelId
            };
        }

        return null;
    }

    private async loadAndRespond(question: string): Promise<{
        response: string;
        modelId: string;
    }> {
        // æŒ‰ä¼˜å…ˆçº§å°è¯•åŠ è½½æ¨¡å‹
        const modelsToTry = this.FAST_MODELS.filter(m => m.id !== 'instant');

        for (const modelConfig of modelsToTry) {
            try {
                console.log(`ğŸ”„ å°è¯•åŠ è½½æ¨¡å‹: ${modelConfig.name}`);

                // æ£€æŸ¥ç¼“å­˜çš„æ¨¡å‹çŠ¶æ€
                const cachedState = await modelCacheService.getCachedModelState(modelConfig.id);

                let model;
                if (cachedState) {
                    console.log('ğŸ“– ä»ç¼“å­˜æ¢å¤æ¨¡å‹çŠ¶æ€:', modelConfig.name);
                    model = await this.restoreModelFromCache(modelConfig.id, cachedState);
                } else {
                    // è®¾ç½®è¶…æ—¶æ—¶é—´ï¼ˆæ ¹æ®æ¨¡å‹å¤§å°ï¼‰
                    const timeout = this.getTimeoutForModel(modelConfig);
                    model = await this.loadModelWithTimeout(modelConfig, timeout);

                    // ç¼“å­˜æ¨¡å‹çŠ¶æ€
                    await modelCacheService.cacheModelState(modelConfig.id, model.state, '1.0');
                }

                this.currentModel = modelConfig.id;
                const response = await this.generateWithModel(model, question);

                // ç¼“å­˜å“åº”
                await modelCacheService.cacheResponse(question, response, modelConfig.id);

                return {
                    response,
                    modelId: modelConfig.id
                };

            } catch (error) {
                const errorMessage = error instanceof Error ? error.message : String(error);
                console.log(`âŒ æ¨¡å‹ ${modelConfig.name} åŠ è½½å¤±è´¥:`, errorMessage);
                continue;
            }
        }

        throw new Error('æ‰€æœ‰æ¨¡å‹åŠ è½½å¤±è´¥');
    }

    private getTimeoutForModel(modelConfig: ModelConfig): number {
        // æ ¹æ®æ¨¡å‹å¤§å°è®¾ç½®è¶…æ—¶æ—¶é—´
        const sizeNum = parseInt(modelConfig.size);
        if (sizeNum <= 50) return 30000;   // 30ç§’
        if (sizeNum <= 150) return 60000;  // 1åˆ†é’Ÿ
        if (sizeNum <= 700) return 180000; // 3åˆ†é’Ÿ
        return 300000; // 5åˆ†é’Ÿ
    }

    private async loadModelWithTimeout(modelConfig: ModelConfig, timeout: number): Promise<any> {
        return Promise.race([
            this.loadModel(modelConfig),
            new Promise((_, reject) =>
                setTimeout(() => reject(new Error(`åŠ è½½è¶…æ—¶ (${timeout / 1000}s)`)), timeout)
            )
        ]);
    }

    private async loadModel(modelConfig: ModelConfig): Promise<any> {
        console.log(`ğŸ“¥ æ­£åœ¨åŠ è½½æ¨¡å‹: ${modelConfig.name}`);

        try {
            // åŠ¨æ€å¯¼å…¥ Transformers.js
            const { pipeline } = await import('@huggingface/transformers');

            // æ ¹æ®æ¨¡å‹ç±»å‹é€‰æ‹©åˆé€‚çš„ pipeline
            let model;
            if (modelConfig.id.includes('gpt') || modelConfig.id.includes('TinyLlama')) {
                // æ–‡æœ¬ç”Ÿæˆæ¨¡å‹
                model = await pipeline('text-generation', modelConfig.id, {
                    device: 'webgpu', // ä¼˜å…ˆä½¿ç”¨ WebGPU
                    dtype: 'fp16'
                });
            } else {
                // é»˜è®¤ä½¿ç”¨æ–‡æœ¬ç”Ÿæˆ
                model = await pipeline('text-generation', modelConfig.id);
            }

            console.log(`âœ… æ¨¡å‹åŠ è½½æˆåŠŸ: ${modelConfig.name}`);

            return {
                id: modelConfig.id,
                config: modelConfig,
                pipeline: model,
                state: {
                    loaded: true,
                    timestamp: Date.now(),
                    version: '1.0'
                }
            };
        } catch (error) {
            console.error(`âŒ æ¨¡å‹åŠ è½½å¤±è´¥: ${modelConfig.name}`, error);
            throw error;
        }
    }

    private async generateWithModel(model: any, question: string): Promise<string> {
        console.log(`ğŸ¤– ä½¿ç”¨æ¨¡å‹ ${model.id} ç”Ÿæˆå›å¤`);

        try {
            if (!model.pipeline) {
                throw new Error('æ¨¡å‹ pipeline æœªåˆå§‹åŒ–');
            }

            // æ„å»ºé€‚åˆé‡‘èåˆ†æçš„æç¤ºè¯
            const prompt = `ä½œä¸ºä¸€ä¸ªä¸“ä¸šçš„é‡‘èæŠ€æœ¯åˆ†æå¸ˆï¼Œè¯·å›ç­”ä»¥ä¸‹é—®é¢˜ï¼š${question}\n\nå›ç­”ï¼š`;

            // ä½¿ç”¨æ¨¡å‹ç”Ÿæˆå›å¤
            const result = await model.pipeline(prompt, {
                max_new_tokens: 150,
                temperature: 0.7,
                do_sample: true,
                top_p: 0.9,
                repetition_penalty: 1.1
            });

            // æå–ç”Ÿæˆçš„æ–‡æœ¬
            let response = '';
            if (Array.isArray(result) && result.length > 0) {
                response = result[0].generated_text || '';
            } else if (result.generated_text) {
                response = result.generated_text;
            }

            // æ¸…ç†å›å¤ï¼ˆç§»é™¤æç¤ºè¯éƒ¨åˆ†ï¼‰
            if (response.includes('å›ç­”ï¼š')) {
                response = response.split('å›ç­”ï¼š')[1].trim();
            }

            // å¦‚æœå›å¤ä¸ºç©ºæˆ–å¤ªçŸ­ï¼Œæä¾›å¤‡ç”¨å›å¤
            if (!response || response.length < 10) {
                response = `åŸºäº ${model.id} æ¨¡å‹åˆ†æï¼šæ‚¨çš„é—®é¢˜å¾ˆæœ‰ä»·å€¼ã€‚åœ¨é‡‘èæŠ€æœ¯åˆ†æä¸­ï¼Œå»ºè®®ç»“åˆå…·ä½“çš„å¸‚åœºæ•°æ®å’Œå›¾è¡¨è¿›è¡Œæ·±å…¥åˆ†æã€‚`;
            }

            return response;

        } catch (error) {
            console.error('âŒ æ¨¡å‹æ¨ç†å¤±è´¥:', error);
            // è¿”å›é”™è¯¯æ—¶çš„å¤‡ç”¨å›å¤
            return `æŠ±æ­‰ï¼Œ${model.id} æ¨¡å‹å½“å‰æ— æ³•å¤„ç†æ‚¨çš„é—®é¢˜ã€‚è¯·å°è¯•é‡æ–°è¡¨è¿°æˆ–ç¨åå†è¯•ã€‚`;
        }
    }

    private async restoreModelFromCache(modelId: string, cachedState: any): Promise<any> {
        // ä»ç¼“å­˜æ¢å¤æ¨¡å‹
        console.log('âš¡ ä»ç¼“å­˜æ¢å¤æ¨¡å‹:', modelId);

        return {
            id: modelId,
            state: cachedState
        };
    }

    private initInstantResponses(): void {
        // å¤§å¹…å‡å°‘å³æ—¶å›å¤åº“ï¼Œåªä¿ç•™æœ€åŸºç¡€çš„æœ¯è¯­
        const responses = new Map([
            ['å¸®åŠ©', 'æˆ‘æ˜¯é‡‘èæŠ€æœ¯åˆ†æåŠ©æ‰‹ï¼Œå¯ä»¥å›ç­”Kçº¿ã€æŠ€æœ¯æŒ‡æ ‡ã€äº¤æ˜“ç­–ç•¥ç­‰ç›¸å…³é—®é¢˜ã€‚'],
            ['help', 'æˆ‘æ˜¯é‡‘èæŠ€æœ¯åˆ†æåŠ©æ‰‹ï¼Œå¯ä»¥å›ç­”Kçº¿ã€æŠ€æœ¯æŒ‡æ ‡ã€äº¤æ˜“ç­–ç•¥ç­‰ç›¸å…³é—®é¢˜ã€‚']
        ]);

        this.instantResponses = responses;
    }

    private getInstantResponse(question: string): string | null {
        const lowerQuestion = question.toLowerCase().trim();

        // åªå¯¹éå¸¸åŸºç¡€çš„å¸®åŠ©ä¿¡æ¯è¿›è¡Œç²¾ç¡®åŒ¹é…
        for (const [keyword, response] of this.instantResponses.entries()) {
            if (lowerQuestion === keyword) {
                console.log('âš¡ å³æ—¶å›å¤åŒ¹é…:', keyword);
                return response;
            }
        }

        // å®Œå…¨ç§»é™¤æ¨¡ç³ŠåŒ¹é…ï¼Œè®©æ‰€æœ‰å®é™…é—®é¢˜éƒ½èµ°æ¨¡å‹æ¨ç†
        console.log('ğŸ”„ é—®é¢˜æœªåŒ¹é…å³æ—¶å›å¤ï¼Œå°†ä½¿ç”¨æ¨¡å‹æ¨ç†');
        return null;
    }

    // è·å–æœåŠ¡çŠ¶æ€
    async getServiceStatus(): Promise<{
        isInitialized: boolean;
        currentModel: string | null;
        cacheStats: any;
        availableModels: ModelConfig[];
    }> {
        const cacheStats = this.isInitialized
            ? await modelCacheService.getCacheStats()
            : null;

        return {
            isInitialized: this.isInitialized,
            currentModel: this.currentModel,
            cacheStats,
            availableModels: this.FAST_MODELS
        };
    }

    // é¢„åŠ è½½æ¨¡å‹
    async preloadModel(modelId: string): Promise<boolean> {
        try {
            const modelConfig = this.FAST_MODELS.find(m => m.id === modelId);
            if (!modelConfig || modelConfig.id === 'instant') {
                return false;
            }

            console.log('ğŸ”„ é¢„åŠ è½½æ¨¡å‹:', modelConfig.name);
            const model = await this.loadModel(modelConfig);
            await modelCacheService.cacheModelState(modelId, model.state, '1.0');

            return true;
        } catch (error) {
            console.error('âŒ é¢„åŠ è½½æ¨¡å‹å¤±è´¥:', error);
            return false;
        }
    }

    // æ¸…ç†ç¼“å­˜
    async clearCache(): Promise<void> {
        await modelCacheService.clearAllCache();
        await swManager.clearCache();
        this.currentModel = null;
        console.log('ğŸ—‘ï¸ æ‰€æœ‰ç¼“å­˜å·²æ¸…ç†');
    }
}

export const fastChatService = new FastChatService();